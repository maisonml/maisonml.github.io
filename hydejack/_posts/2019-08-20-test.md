Trivago Automated Bidding
=========================

Introduction:
-------------

Trivago N.V., marketed with lowercase styling as trivago, is a German transnational technology company specializing in internet-related services and products in the hotel, lodging and meta search fields. The American travel company Expedia Group owns a majority of the company's stock.

Business Model:
---------------

Trivago uses the Cost per Click model (CPC for short). Based on this model, advertisers pay trivago a certain amount every time a user clicks on their hotel deals and is redirected to their site. Advertisers can bid a different CPC per hotel and market (eg., DE, US etc.)

Project Objective: Automated Bidding Algorithm:
-----------------------------------------------

Automated Bidding is an algorithm that assists advertisers run successful campaigns on trivago by optimizing their CPC bidding. One of the core components of the Automated Bidding algorithm is predicting the number of bookings for a given hotel, advertiser and market. This is essential for optimizing the CPC bids of a campaign since the bookings are what generate the actual value for the advertiser.

Data:
-----

The number of bookings that were generated per year, week\_of\_year, advertiser\_id and hotel\_id combination in the (imaginary) IM platform from the first week of 2017 to the 6th week of 2018. Every row has a unique identifier. An additional 36 variables are in the dataset in addition to the identifier and the target variable.

WorkFlow:
=========

The first step is to determine where the Automated Bidding Algorithm will run in the trivago workflow for advertisers. The first and obvious understanding is that this algorithm will automate the decision making of the advertisers, so the advertisers are the end users of the project. Both clicks and booking are conversion events and a booking event can occur only if a click event has occured first. In our model to predict the probability of a booking, we will use the following types of variables:

1.  Hotel Variables (Like location, stars, last\_renovation and so on)
2.  Advertiser variables (Like Connections)
3.  Time and Seasonality Variables (Like Week of the year, month of the year and year)
4.  Ad Performance variables (Like BeatRate, MeetRate, LoseRate, Clicks)

Exploratory Data Analysis:
--------------------------

Let's do an exploratory analyses over the train data set.

Number of rows in the train data set is:

``` r
options(warn=-1)
setwd("E:/Dhivya/AutomatedBidding")
train <- read.csv("train_set.csv")
nrow(train)
```

    ## [1] 595848

Let's get a glimpse of the train data set:

``` r
head(train,5)
```

    ##                  id yyear week_of_year advertiser_id market hotel_id
    ## 1 201716IM512425060  2017           16          5124     IM    25060
    ## 2  20176IM135625060  2017            6          1356     IM    25060
    ## 3 201728IM512425060  2017           28          5124     IM    25060
    ## 4 201726IM135625060  2017           26          1356     IM    25060
    ## 5 201737IM107125060  2017           37          1071     IM    25060
    ##   clicks   cost bookings top_pos beat  meet lose impressions city_id stars
    ## 1      2   1104        0       1    1  4388  988        5309   39332     3
    ## 2     34  33281       11     174   37 11634 1802       13455   39332     3
    ## 3      3   2001        0       0   24  3975 2719        6666   39332     3
    ## 4    218 282394       21    1467   55  5182 1256        6444   39332     3
    ## 5      5   4600        0      42   NA    NA   NA        5428   39332     3
    ##   rating distance_to_city_centre poi_image longitude latitude
    ## 1   1000                    1570         0 -1.885049 52.47071
    ## 2   1000                    1570         0 -1.885049 52.47071
    ## 3   1000                    1570         0 -1.885049 52.47071
    ## 4   1000                    1570         0 -1.885049 52.47071
    ## 5   1000                    1570         0 -1.885049 52.47071
    ##   last_renovation spa_hotel country_hotel convention_hotel
    ## 1            2012        NA            NA               NA
    ## 2            2012        NA            NA               NA
    ## 3            2012        NA            NA               NA
    ## 4            2012        NA            NA               NA
    ## 5            2012        NA            NA               NA
    ##   beach_front_hotel luxury_hotel city_hotel_centrally_located
    ## 1                NA           NA                            1
    ## 2                NA           NA                            1
    ## 3                NA           NA                            1
    ## 4                NA           NA                            1
    ## 5                NA           NA                            1
    ##   health_resortrehab_hotel club_club_hotel airport_hotel senior_hotel
    ## 1                       NA              NA            NA           NA
    ## 2                       NA              NA            NA           NA
    ## 3                       NA              NA            NA           NA
    ## 4                       NA              NA            NA           NA
    ## 5                       NA              NA            NA           NA
    ##   eco_friendly_hotel family_hotel total_images total_hq_images
    ## 1                 NA           NA          105              41
    ## 2                 NA           NA          105              41
    ## 3                 NA           NA          105              41
    ## 4                 NA           NA          105              41
    ## 5                 NA           NA          105              41
    ##   advertiser_connections
    ## 1                    269
    ## 2                    269
    ## 3                    269
    ## 4                    269
    ## 5                    269

Let's find the unique number of hotels and advertisers in the data set:

``` r
length(unique(train$hotel_id))
```

    ## [1] 1784

``` r
length(unique(train$advertiser_id))
```

    ## [1] 105

The target variable is bookings, let's do a univariate:

``` r
summary(train$bookings)
```

    ##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
    ##   0.000   0.000   0.000   3.315   1.000 557.000

Sample Bi-Variate Study
-----------------------

Let's bin the target variable to see the proportion in each bin: We see that for 75.29% of times, an advertiser had less than 1 booking in a week for a hotel

``` r
train$BookingsBucket <- cut(train$bookings, c(0,1,5,20,600), include.lowest = TRUE)
library(plyr)
train$Row <- 1
collapse <- ddply(train[,c("BookingsBucket","Row")],.(BookingsBucket),summarize,Count=sum(Row))
collapse$Proportion <- round((collapse$Count/ 595848)*100,2)
collapse
```

    ##   BookingsBucket  Count Proportion
    ## 1          [0,1] 448604      75.29
    ## 2          (1,5]  59811      10.04
    ## 3         (5,20]  60219      10.11
    ## 4       (20,600]  27214       4.57

Let's do a bi-variate for the booking buckets with few of the independent variables as a sample. Total images is inversely related to the number of bookings as can be seen in the bivariate below, where the booking rate is highest for total images less than 60.

``` r
source("http://pcwww.liv.ac.uk/~william/R/crosstab.r")
train$TotalImagesBucket <- cut(train$total_images, c(0,60,90,120,600), include.lowest = TRUE)
crosstab(train, row.vars = "TotalImagesBucket", col.vars = 'BookingsBucket', type=c("f","r"))
```

    ##                                      Count                                             Row %                                        
    ##                   BookingsBucket     [0,1]     (1,5]    (5,20]  (20,600]       Sum     [0,1]     (1,5]    (5,20]  (20,600]       Sum
    ## TotalImagesBucket                                                                                                                   
    ## [0,60]                           105159.00  16998.00  18623.00   9343.00 150123.00     70.05     11.32     12.41      6.22    100.00
    ## (60,90]                          127041.00  17275.00  17310.00   7789.00 169415.00     74.99     10.20     10.22      4.60    100.00
    ## (90,120]                          95824.00  11857.00  12146.00   5736.00 125563.00     76.32      9.44      9.67      4.57    100.00
    ## (120,600]                        120580.00  13681.00  12140.00   4346.00 150747.00     79.99      9.08      8.05      2.88    100.00

Let's engineer 3 variables: BeatRate, MeetRate and LoseRate- defined by the ratio of beats, meets and loses to the overall number of impressions respectively. These variables give an idea of how competitive the deals are from the advertisers. Also let's deal with outliers in these variables. We see that booking rates are higher as the meet rates get higher. Booking rates are considerably lower when lose rates are higher.

``` r
train$impressions[train$impressions==0] <- 0.01
train$BeatRate <- train$beat/ train$impressions
train$LoseRate <- train$lose/ train$impressions
train$MeetRate <- train$meet/ train$impressions
train$MeetRate[train$MeetRate >1] <- 1
train$BeatRate[train$BeatRate >1] <-1
train$LoseRate[train$LoseRate >1] <- 1
train$MeetRateBucket <- cut(train$MeetRate, c(0,0.25,0.5,0.75,1), include.lowest = TRUE)
crosstab(train, row.vars = "MeetRateBucket", col.vars = 'BookingsBucket', type=c("f","r"))
```

    ##                                   Count                                             Row %                                        
    ##                BookingsBucket     [0,1]     (1,5]    (5,20]  (20,600]       Sum     [0,1]     (1,5]    (5,20]  (20,600]       Sum
    ## MeetRateBucket                                                                                                                   
    ## [0,0.25]                      282925.00  30304.00  25591.00  10742.00 349562.00     80.94      8.67      7.32      3.07    100.00
    ## (0.25,0.5]                     40317.00   8947.00  10087.00   4555.00  63906.00     63.09     14.00     15.78      7.13    100.00
    ## (0.5,0.75]                     33829.00   8815.00  10877.00   5390.00  58911.00     57.42     14.96     18.46      9.15    100.00
    ## (0.75,1]                       42023.00  10050.00  12709.00   6318.00  71100.00     59.10     14.14     17.87      8.89    100.00

``` r
train$LoseRateBucket <- cut(train$LoseRate, c(0,0.25,0.5,0.75,1), include.lowest = TRUE)
crosstab(train, row.vars = "LoseRateBucket", col.vars = 'BookingsBucket', type=c("f","r"))
```

    ##                                   Count                                             Row %                                        
    ##                BookingsBucket     [0,1]     (1,5]    (5,20]  (20,600]       Sum     [0,1]     (1,5]    (5,20]  (20,600]       Sum
    ## LoseRateBucket                                                                                                                   
    ## [0,0.25]                       28104.00   8107.00  11420.00   6370.00  54001.00     52.04     15.01     21.15     11.80    100.00
    ## (0.25,0.5]                     32685.00   9050.00  11615.00   5909.00  59259.00     55.16     15.27     19.60      9.97    100.00
    ## (0.5,0.75]                     37799.00   9975.00  12202.00   5948.00  65924.00     57.34     15.13     18.51      9.02    100.00
    ## (0.75,1]                      300506.00  30984.00  24027.00   8778.00 364295.00     82.49      8.51      6.60      2.41    100.00

Seasonal Variables:
-------------------

Week 7 is Valentine's day week. Let's engineer a variable called isWeek7. We see the booking rates are particularly high for Valentine's day weekend.

``` r
train$isWeek7[train$week_of_year==7] <- 1
train$isWeek7[is.na(train$isWeek7)] <- 0
crosstab(train, row.vars = "isWeek7", col.vars = 'BookingsBucket', type=c("f","r"))
```

    ##                            Count                                             Row %                                        
    ##         BookingsBucket     [0,1]     (1,5]    (5,20]  (20,600]       Sum     [0,1]     (1,5]    (5,20]  (20,600]       Sum
    ## isWeek7                                                                                                                   
    ## 0                      440622.00  58778.00  59104.00  26495.00 584999.00     75.32     10.05     10.10      4.53    100.00
    ## 1                        7982.00   1033.00   1115.00    719.00  10849.00     73.57      9.52     10.28      6.63    100.00

Let's engineer another variable called Month. We see that Feb has the highest booking rates.

``` r
train$Month[train$week_of_year %in% c(1:4)] <- "Jan"
train$Month[train$week_of_year %in% c(5:8)] <- "Feb"
train$Month[train$week_of_year %in% c(9:13)] <- "Mar"
train$Month[train$week_of_year %in% c(14:17)] <- "Apr"
train$Month[train$week_of_year %in% c(18:22)] <- "May"
train$Month[train$week_of_year %in% c(23:26)] <- "Jun"
train$Month[train$week_of_year %in% c(27:30)] <- "Jul"
train$Month[train$week_of_year %in% c(31:35)] <- "Aug"
train$Month[train$week_of_year %in% c(36:39)] <- "Sep"
train$Month[train$week_of_year %in% c(40:43)] <- "Oct"
train$Month[train$week_of_year %in% c(44:48)] <- "Nov"
train$Month[train$week_of_year %in% c(49:52)] <- "Dec"
crosstab(train, row.vars = "Month", col.vars = 'BookingsBucket', type=c("f","r"))
```

    ##                         Count                                        Row %                                    
    ##       BookingsBucket    [0,1]    (1,5]   (5,20] (20,600]      Sum    [0,1]    (1,5]   (5,20] (20,600]      Sum
    ## Month                                                                                                         
    ## Apr                  29845.00  3776.00  3747.00  1746.00 39114.00    76.30     9.65     9.58     4.46   100.00
    ## Aug                  41060.00  4916.00  5088.00  2182.00 53246.00    77.11     9.23     9.56     4.10   100.00
    ## Dec                  24965.00  3949.00  3418.00  1026.00 33358.00    74.84    11.84    10.25     3.08   100.00
    ## Feb                  45678.00  6579.00  7365.00  4121.00 63743.00    71.66    10.32    11.55     6.47   100.00
    ## Jan                  57483.00  8310.00  9079.00  4269.00 79141.00    72.63    10.50    11.47     5.39   100.00
    ## Jul                  34033.00  3982.00  3773.00  1872.00 43660.00    77.95     9.12     8.64     4.29   100.00
    ## Jun                  35307.00  4074.00  3738.00  1350.00 44469.00    79.40     9.16     8.41     3.04   100.00
    ## Mar                  41010.00  5112.00  5443.00  2782.00 54347.00    75.46     9.41    10.02     5.12   100.00
    ## May                  39002.00  4944.00  4820.00  2032.00 50798.00    76.78     9.73     9.49     4.00   100.00
    ## Nov                  37025.00  5433.00  5071.00  2070.00 49599.00    74.65    10.95    10.22     4.17   100.00
    ## Oct                  30712.00  4489.00  4418.00  2198.00 41817.00    73.44    10.73    10.57     5.26   100.00
    ## Sep                  32484.00  4247.00  4259.00  1566.00 42556.00    76.33     9.98    10.01     3.68   100.00

Machine Learning
----------------

Xtreme Gradient Boosting is the algorithm that we are going to use. XGB has the following advantages: 1. Accurate and fast 2. categorical features need not be one hot encoded 3. Outliers are handled 4. Correlated features are handled 5. Model tuning is easy to learn 6. Missing values are handled 7. Has a feature selection method

The following are the features in the 1st iteration of the model:

``` r
features <- c("yyear","week_of_year","Month","isWeek7","hotel_id","top_pos","BeatRate","MeetRate",         
              "city_id","rating","poi_image", "LoseRate", "clicks", "cost",
              "longitude","latitude","last_renovation","spa_hotel","country_hotel",              
              "convention_hotel","beach_front_hotel","luxury_hotel","city_hotel_centrally_located",
              "health_resortrehab_hotel","club_club_hotel","airport_hotel","senior_hotel",                
              "eco_friendly_hotel","family_hotel","total_images","total_hq_images",            
              "advertiser_connections")
features
```

    ##  [1] "yyear"                        "week_of_year"                
    ##  [3] "Month"                        "isWeek7"                     
    ##  [5] "hotel_id"                     "top_pos"                     
    ##  [7] "BeatRate"                     "MeetRate"                    
    ##  [9] "city_id"                      "rating"                      
    ## [11] "poi_image"                    "LoseRate"                    
    ## [13] "clicks"                       "cost"                        
    ## [15] "longitude"                    "latitude"                    
    ## [17] "last_renovation"              "spa_hotel"                   
    ## [19] "country_hotel"                "convention_hotel"            
    ## [21] "beach_front_hotel"            "luxury_hotel"                
    ## [23] "city_hotel_centrally_located" "health_resortrehab_hotel"    
    ## [25] "club_club_hotel"              "airport_hotel"               
    ## [27] "senior_hotel"                 "eco_friendly_hotel"          
    ## [29] "family_hotel"                 "total_images"                
    ## [31] "total_hq_images"              "advertiser_connections"

The following variable is not included in the first cut model:

1.  advertiser\_id because we want to be unbiased towards all our advertisers

Convert columns of class "Character" to "factor"

``` r
train[sapply(train, is.character)] <- lapply(train[sapply(train, is.character)],as.factor)
```

To validate the model over a test data set, we are splitting the train data set into train\_sub and test\_sub

``` r
set.seed(1234)
index <- sample(nrow(train), nrow(train)/2)
train_sub <- train[index,]
test_sub <- train[-index,]
```

Building a first cut XGBoost model using "rmse" evaluation metric

Parameters:
-----------

We have a gbtree booster, we have set max tree depth of 3 to avoid overfitting of non existent relationships, we have nrounds to 1000 to ensure a good fit and the learning rate is set to 0.01 subsequently to avoid overfitting.

``` r
library(xgboost)
model_regularized <- xgboost(data        = data.matrix(train_sub[,features]),
                                  label       = train_sub$bookings,
                                  silent=0,
                                  booster="gbtree",
                                  eta = 0.01, verbose = 0,
                                  max_depth = 3,
                                  min_child_weight=6, max_delta_step=10,
                                  nrounds     = 1000,
                                  subsample = 0.5,
                                  colsample_bytree = 0.5,
                                  seed = 1234,
                                  objective   = "reg:linear",
                                  eval_metric = "rmse")
save(model_regularized,file="model_regularized.RData")
```

Let's predict over the test data set and find the error and RMSE values

``` r
test_sub$Predictions <- predict(model_regularized, data.matrix(test_sub[,features]))
test_sub$Predictions[test_sub$Predictions<=0] <-0
test_sub$error <- test_sub$bookings- test_sub$Predictions
rmse <- function(error)
{sqrt(mean(error^2))}
rmse(test_sub$error)
```

    ## [1] 6.127038

The RMSE of the train data set should be similar to the RMSE of the test data set to check for overfitting

``` r
train_sub$Predictions <- predict(model_regularized, data.matrix(train_sub[,features]))
train_sub$Predictions[train_sub$Predictions<=0] <-0
train_sub$error <- train_sub$bookings- train_sub$Predictions
rmse(train_sub$error)
```

    ## [1] 5.8405

Let us find the feature importance of the variables. When implementing the model in production, only 10 to 15 of the most predictive variables should be taken for the following reasons:

1.  To avoid slowing down the production platform
2.  The presence of more features doesn't add much to the model's predictive power
3.  For easier maintenance of models due to variable decay

``` r
importance <- xgb.importance(feature_names = features, model=model_regularized)
importance
```

    ##                          Feature         Gain        Cover    Frequency
    ##  1:                       clicks 5.994429e-01 3.924088e-01 0.2131899642
    ##  2:                         cost 2.392347e-01 2.254928e-01 0.1294623656
    ##  3:                      top_pos 9.084989e-02 1.729546e-01 0.0944802867
    ##  4:                     latitude 1.317828e-02 1.934687e-02 0.0719713262
    ##  5:                    longitude 1.242220e-02 3.505090e-02 0.1109677419
    ##  6:                     LoseRate 8.630712e-03 4.269652e-02 0.0417204301
    ##  7:                 total_images 7.257730e-03 1.867903e-02 0.0511827957
    ##  8:              total_hq_images 6.345331e-03 7.938368e-03 0.0441577061
    ##  9:                     MeetRate 5.622406e-03 1.199422e-02 0.0394265233
    ## 10:                     BeatRate 5.441069e-03 1.733193e-02 0.0414336918
    ## 11:                      city_id 5.207216e-03 7.373243e-03 0.0491756272
    ## 12:                 luxury_hotel 2.594704e-03 1.172976e-02 0.0270967742
    ## 13:                     hotel_id 8.187772e-04 1.874068e-03 0.0162007168
    ## 14:       advertiser_connections 7.429718e-04 4.571864e-03 0.0164874552
    ## 15:                 week_of_year 6.601984e-04 2.310198e-02 0.0167741935
    ## 16:              last_renovation 4.470077e-04 1.621637e-03 0.0106093190
    ## 17:            beach_front_hotel 1.885007e-04 4.455773e-04 0.0030107527
    ## 18:                country_hotel 1.511325e-04 1.578009e-03 0.0032974910
    ## 19: city_hotel_centrally_located 1.448702e-04 1.031717e-04 0.0030107527
    ## 20:                    spa_hotel 1.348176e-04 1.451630e-03 0.0032974910
    ## 21:                       rating 1.122495e-04 1.660779e-04 0.0025806452
    ## 22:           eco_friendly_hotel 9.901885e-05 3.305829e-04 0.0028673835
    ## 23:     health_resortrehab_hotel 9.894007e-05 1.426069e-04 0.0021505376
    ## 24:                        Month 6.839672e-05 1.315783e-03 0.0024372760
    ## 25:                        yyear 5.291741e-05 2.958015e-04 0.0020071685
    ## 26:                 family_hotel 3.913318e-05 1.718372e-06 0.0007168459
    ## 27:             convention_hotel 1.075500e-05 1.901843e-07 0.0001433692
    ## 28:                airport_hotel 3.181233e-06 2.335911e-06 0.0001433692
    ##                          Feature         Gain        Cover    Frequency

From the importance table, we choose the top 15 variables with highest Gain values. These are the variables with the highest predictive power. We also see that these variables are a good mix of ad level, advertiser level, hotel level and time variables.

\[1\] "clicks" "cost" "top\_pos" "latitude"
\[5\] "longitude" "LoseRate" "total\_images" "total\_hq\_images"
\[9\] "city\_id" "BeatRate" "MeetRate" "luxury\_hotel"
\[13\] "hotel\_id" "week\_of\_year" "advertiser\_connections"

We build a subsequent iteration of the model using the above features and validate for the test and train RMSE.

``` r
features_last <- c("clicks","cost","top_pos","latitude","longitude","LoseRate","total_images",          "total_hq_images","city_id","BeatRate","MeetRate","luxury_hotel","hotel_id","week_of_year","advertiser_connections")
model_regularized_last <- xgboost(data        = data.matrix(train_sub[,features_last]),
                                  label       = train_sub$bookings,
                                  silent=0,
                                  booster="gbtree",verbose = 0,
                                  eta = 0.01,
                                  max_depth = 3,
                                  min_child_weight=6, max_delta_step=10,
                                  nrounds     = 1000,
                                  subsample = 0.5,
                                  colsample_bytree = 0.5,
                                  seed = 1234,
                                  objective   = "reg:linear",
                                  eval_metric = "rmse")
save(model_regularized_last,file="model_regularized_last.RData")
test_sub$Predictions <- predict(model_regularized_last, data.matrix(test_sub[,features_last]))
test_sub$Predictions[test_sub$Predictions<=0] <-0
test_sub$error <- test_sub$bookings- test_sub$Predictions
rmse <- function(error)
{sqrt(mean(error^2))}
rmse(test_sub$error)
```

    ## [1] 6.165917

``` r
train_sub$Predictions <- predict(model_regularized_last, data.matrix(train_sub[,features_last]))
train_sub$Predictions[train_sub$Predictions<=0] <-0
train_sub$error <- train_sub$bookings- train_sub$Predictions
rmse(train_sub$error)
```

    ## [1] 5.880644

Submission File:
----------------

Running the model over the test data and creating the submission file

``` r
test <- read.csv("test_set.csv")
test$impressions[test$impressions==0] <- 0.01
test$BeatRate <- test$beat/ test$impressions
test$LoseRate <- test$lose/ test$impressions
test$MeetRate <- test$meet/ test$impressions
test$MeetRate[test$MeetRate >1] <- 1
test$BeatRate[test$BeatRate >1] <-1
test$LoseRate[test$LoseRate >1] <- 1
test$isWeek7[test$week_of_year==7] <- 1
test$isWeek7[is.na(test$isWeek7)] <- 0
test$Month[test$week_of_year %in% c(1:4)] <- "Jan"
test$Month[test$week_of_year %in% c(5:8)] <- "Feb"
test$Month[test$week_of_year %in% c(9:13)] <- "Mar"
test$Month[test$week_of_year %in% c(14:17)] <- "Apr"
test$Month[test$week_of_year %in% c(18:22)] <- "May"
test$Month[test$week_of_year %in% c(23:26)] <- "Jun"
test$Month[test$week_of_year %in% c(27:30)] <- "Jul"
test$Month[test$week_of_year %in% c(31:35)] <- "Aug"
test$Month[test$week_of_year %in% c(36:39)] <- "Sep"
test$Month[test$week_of_year %in% c(40:43)] <- "Oct"
test$Month[test$week_of_year %in% c(44:48)] <- "Nov"
test$Month[test$week_of_year %in% c(49:52)] <- "Dec"
test[sapply(test, is.character)] <- lapply(test[sapply(test, is.character)],as.factor)
```

``` r
test$pred_bookings <- predict(model_regularized_last, data.matrix(test[,features_last]))
test$pred_bookings[test$pred_bookings<=0] <-0
submission_file <- test[,c("id","pred_bookings")]
save(submission_file,file="submission_file.RData")
write.csv(submission_file,"submission_file.csv")
```

Conclusions:
------------

This model can be implemented in Production after a A/B Test. The model has to be maintained and checked for performance regularly to avoid decay over time.
